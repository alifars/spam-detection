{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table(\"SMSSpamCollection\", header = None, names = [\"labels\", \"texts\"])\n",
    "\n",
    "raw_labels = data[\"labels\"]\n",
    "raw_features = data.drop(\"labels\", axis = 1)\n",
    "raw_features.shape\n",
    "raw_labels.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot encode the labels\n",
    "we need to convert discrete features to real value to feed it into scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'spam': 1, 'ham': 0}\n",
    "encoded_labels  = raw_labels.apply(lambda x: label_dict[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text vectorization\n",
    "\n",
    "messages are string and to make them usable for any machine learning algorithm, they should be converted to numerical vectors. the easiest way is to build a term-document matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8713)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "vectorized_features = count_vectorizer.fit_transform(raw_features[\"texts\"])\n",
    "\n",
    "vectorized_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 8713)\n",
      "(1115, 8713)\n",
      "(4457,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(vectorized_features, encoded_labels, test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.986\n",
      "recall: 0.887\n",
      "f_score: 0.965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, fbeta_score, f1_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "f_score = fbeta_score(y_true=y_test, y_pred=y_pred, beta = 0.5)\n",
    "print(\"precision: {:.3f}\".format(precision))\n",
    "print(\"recall: {:.3f}\".format(recall))\n",
    "print(\"f_score: {:.3f}\".format(f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all metrics look good, what might went wrong, I am suspicious, let's do a cross validation to make sure the model is not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.878 +- 0.047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, vectorized_features, encoded_labels, cv=7, scoring='precision')\n",
    "\n",
    "mean = scores.mean()\n",
    "std = scores.std()\n",
    "print(\"precision: {:.3f} +- {:.3f}\".format(mean, 2*std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
